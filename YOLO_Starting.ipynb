{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "044462b9-caf2-4001-a997-da89ce235215",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ultralytics import YOLO \n",
    "import cv2\n",
    "import cvzone\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "824cf65f-b03e-4be3-9df0-63ec0f588211",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = YOLO(\"yolov8l.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c611c6d7-e4d1-40a6-85e3-6d02bbd799f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "className = [\"person\", \"bicycle\", \"car\", \"motorbike\", \"aeroplane\", \"bus\", \"train\", \"truck\", \"boat\",\"traffic light\", \"fire hydrant\", \"stop sign\", \"parking meter\", \"bench\", \"bird\", \"cat\",\"dog\", \"horse\", \"sheep\", \"cow\", \"elephant\", \"bear\", \"zebra\", \"giraffe\", \"backpack\", \"umbrella\",\"handbag\", \"tie\", \"suitcase\", \"frisbee\", \"skis\", \"snowboard\", \"sports ball\", \"kite\", \"baseball bat\",\"baseball glove\", \"skateboard\", \"surfboard\", \"tennis racket\", \"bottle\", \"wine glass\", \"cup\",\"fork\", \"knife\", \"spoon\", \"bowl\", \"banana\", \"apple\", \"sandwich\", \"orange\", \"broccoli\",\"carrot\", \"hot dog\", \"pizza\", \"donut\", \"cake\", \"chair\", \"sofa\", \"pottedplant\", \"bed\",\"diningtable\", \"toilet\", \"tvmonitor\", \"laptop\", \"mouse\", \"remote\", \"keyboard\", \"cell phone\",\"microwave\", \"oven\", \"toaster\", \"sink\", \"refrigerator\", \"book\", \"clock\", \"vase\", \"scissors\",\"teddy bear\", \"hair drier\", \"toothbrush\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a7d0b65-8a01-4f14-a48d-c69d516393a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#To detect object from image files\n",
    "results = model(\"\",show=True)#Insert the image file location in the Quates\n",
    "cv2.waitKey(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "90df076d-fb8a-4a9c-af6a-bd02c9a68ac3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 384x640 1 person, 56.1ms\n",
      "Speed: 4.4ms preprocess, 56.1ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 57.2ms\n",
      "Speed: 2.0ms preprocess, 57.2ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 61.0ms\n",
      "Speed: 2.4ms preprocess, 61.0ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 74.0ms\n",
      "Speed: 2.7ms preprocess, 74.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 72.3ms\n",
      "Speed: 3.2ms preprocess, 72.3ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 62.3ms\n",
      "Speed: 2.0ms preprocess, 62.3ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 62.7ms\n",
      "Speed: 2.1ms preprocess, 62.7ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 58.3ms\n",
      "Speed: 2.0ms preprocess, 58.3ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 57.2ms\n",
      "Speed: 2.5ms preprocess, 57.2ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 58.5ms\n",
      "Speed: 1.9ms preprocess, 58.5ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 wine glass, 68.7ms\n",
      "Speed: 1.5ms preprocess, 68.7ms inference, 2.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 58.2ms\n",
      "Speed: 2.5ms preprocess, 58.2ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 53.1ms\n",
      "Speed: 2.2ms preprocess, 53.1ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 55.4ms\n",
      "Speed: 3.0ms preprocess, 55.4ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 57.3ms\n",
      "Speed: 3.0ms preprocess, 57.3ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 59.9ms\n",
      "Speed: 2.9ms preprocess, 59.9ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 50.0ms\n",
      "Speed: 2.1ms preprocess, 50.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 55.1ms\n",
      "Speed: 2.0ms preprocess, 55.1ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 56.6ms\n",
      "Speed: 2.5ms preprocess, 56.6ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 56.4ms\n",
      "Speed: 3.5ms preprocess, 56.4ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 52.5ms\n",
      "Speed: 2.0ms preprocess, 52.5ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 64.6ms\n",
      "Speed: 2.0ms preprocess, 64.6ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 73.3ms\n",
      "Speed: 3.5ms preprocess, 73.3ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 56.9ms\n",
      "Speed: 2.0ms preprocess, 56.9ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 49.7ms\n",
      "Speed: 1.4ms preprocess, 49.7ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 51.9ms\n",
      "Speed: 2.1ms preprocess, 51.9ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 55.8ms\n",
      "Speed: 2.0ms preprocess, 55.8ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 tie, 52.5ms\n",
      "Speed: 2.1ms preprocess, 52.5ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 51.7ms\n",
      "Speed: 1.2ms preprocess, 51.7ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 54.3ms\n",
      "Speed: 1.5ms preprocess, 54.3ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 52.2ms\n",
      "Speed: 3.0ms preprocess, 52.2ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 55.6ms\n",
      "Speed: 1.5ms preprocess, 55.6ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 49.2ms\n",
      "Speed: 1.1ms preprocess, 49.2ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 49.3ms\n",
      "Speed: 1.0ms preprocess, 49.3ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 48.8ms\n",
      "Speed: 1.6ms preprocess, 48.8ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 47.4ms\n",
      "Speed: 2.1ms preprocess, 47.4ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 52.1ms\n",
      "Speed: 2.4ms preprocess, 52.1ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 47.3ms\n",
      "Speed: 1.4ms preprocess, 47.3ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 54.9ms\n",
      "Speed: 2.0ms preprocess, 54.9ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 51.7ms\n",
      "Speed: 2.0ms preprocess, 51.7ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 50.5ms\n",
      "Speed: 2.0ms preprocess, 50.5ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 54.3ms\n",
      "Speed: 2.0ms preprocess, 54.3ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 49.0ms\n",
      "Speed: 2.2ms preprocess, 49.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 52.5ms\n",
      "Speed: 2.0ms preprocess, 52.5ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 53.6ms\n",
      "Speed: 1.5ms preprocess, 53.6ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 56.1ms\n",
      "Speed: 3.0ms preprocess, 56.1ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 57.8ms\n",
      "Speed: 2.0ms preprocess, 57.8ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 55.9ms\n",
      "Speed: 2.3ms preprocess, 55.9ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 94.2ms\n",
      "Speed: 11.5ms preprocess, 94.2ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 51.4ms\n",
      "Speed: 2.3ms preprocess, 51.4ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 56.4ms\n",
      "Speed: 2.6ms preprocess, 56.4ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 60.9ms\n",
      "Speed: 3.0ms preprocess, 60.9ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    }
   ],
   "source": [
    "#To detect object from Webcam or Videos\n",
    "try:\n",
    "    #Uncomment if to detect object from webcam\n",
    "    #cap = cv2.VideoCapture(0)\n",
    "    #Uncomment if to detect object from video file\n",
    "    #cap = cv2.VideoCapture(r\"\")#Insert the file location inside the Quotes\n",
    "    \n",
    "    cap.set(3,1080)\n",
    "    cap.set(4,720)\n",
    "    while True:\n",
    "        success, img = cap.read()\n",
    "\n",
    "        if not success or img is None or img.shape[0] == 0 or img.shape[1] == 0:\n",
    "            print(\"Failed to capture a valid image.\")\n",
    "            break\n",
    "        img = cv2.flip(img,1)\n",
    "        results = model(img, stream=True)\n",
    "        for r in results:\n",
    "            boxes = r.boxes\n",
    "            for box in boxes:\n",
    "                #bounding box Dimensions\n",
    "                x1,y1,x2,y2 = box.xyxy[0]\n",
    "                x1,y1,x2,y2 = int(x1), int(y1), int(x2), int(y2)\n",
    "                #Simple bounding box\n",
    "                #cv2.rectangle(img, (x1,y1), (x2,y2), (255,0,255),3)\n",
    "    \n",
    "                #boundry box with corner \n",
    "                w, h = x2-x1,y2-y1\n",
    "                cvzone.cornerRect(img,bbox=(x1,y1,w,h),l=15)\n",
    "    \n",
    "                #set up the confidence text and the classification\n",
    "                conf = math.ceil((box.conf[0]*100))/100\n",
    "                cls = int(box.cls[0])\n",
    "                cvzone.putTextRect(img, f'{className[cls]}{conf}', (max(0,x1),max(35,y1)),scale= 1,thickness=1)\n",
    "                \n",
    "        cv2.imshow(\"Image\", img)\n",
    "\n",
    "        if cv2.waitKey(1) & 0xFF == ord('q'):  # Press 'q' to exit the loop\n",
    "            break\n",
    "\n",
    "finally:\n",
    "    # Release the camera and destroy all OpenCV windows when done\n",
    "    if cap:\n",
    "        cap.release()\n",
    "    cv2.destroyAllWindows()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
